{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77d3ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f550d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a9b55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = train_X.astype(\"float64\")\n",
    "# train_y = train_y.astype(\"float64\")\n",
    "# test_X = test_X.astype(\"float64\")\n",
    "# test_y = test_X.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd8c3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X/255\n",
    "train_X = train_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73707b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "696fb549",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cf9efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_y(y):\n",
    "    output = []\n",
    "    for i in range(y.shape[0]):\n",
    "        tmp = np.array([0]*10)\n",
    "        tmp[train_y[i]] = 1\n",
    "        output.append(tmp)\n",
    "    return np.array(output).T\n",
    "\n",
    "def get_flatten_X(X):\n",
    "    output = []\n",
    "    for i in range(X.shape[0]):\n",
    "        output.append(X[i].flatten())\n",
    "    return np.array(output).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eeb0f182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y_onehot = get_one_hot_y(train_y)\n",
    "train_X_flatten = get_flatten_X(train_X)\n",
    "test_y_onehot = get_one_hot_y(test_y)\n",
    "test_X_flatten = get_flatten_X(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2cf370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 60000), (10, 10000))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_onehot.shape, test_y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e04f5e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 60000), (784, 10000))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_flatten.shape, test_X_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc527306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n",
      "Y onehot: [1 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPEUlEQVR4nO3dfahVdb7H8c+3KYPSwoeuHS2zifxjEK/KwfzDrl6GO3R70qLiBpU3rpygyTSEbg9EDybFxboFwQG7xig0PYAzY8SFKUIsiWLMzCy7qcORtJOHEMwsijzf+8dZzuxqn98656y911r6fb9A9t7ru/daX9fRz1kPv72WubsAxHVK1Q0AqBYhAARHCADBEQJAcIQAEBwhAARXSQiY2WVm9n9mtsfM7qmihxQz6zGzD81su5ltrUE/z5lZn5ntbJg2zsxeN7Pd2ePYmvX3kJkdyNbhdjO7vML+zjezTWb2sZl9ZGbLsum1WIeJ/kpZh1b2OAEz+4WkTyX9i6T9kv4i6UZ3/7jURhLMrEdSp7t/WXUvkmRm/yTpa0nr3X16Nu2/JB1y98ezIB3r7v9Zo/4ekvS1u6+uoqdGZtYhqcPdt5nZGEnvSVok6d9Vg3WY6O8GlbAOq9gSmCNpj7v/1d2/l/SipIUV9HHCcPc3JR36yeSFktZlz9dp4B9NJQbprzbcvdfdt2XPj0jaJWmyarIOE/2VoooQmCzps4bX+1XiX3iIXNJrZvaemXVV3cwgJrp7b/b8C0kTq2xmEHeY2Y5sd6Gy3ZVGZjZV0ixJ76qG6/An/UklrEMODDY3z91nS/pXSb/NNndrywf26eo2/rtb0kWSZkrqlfREpd1IMrPRkjZIWu7uXzXW6rAOm/RXyjqsIgQOSDq/4fV52bTacPcD2WOfpD9qYBembg5m+5LH9yn7Ku7nR9z9oLsfc/d+Sc+q4nVoZqdp4D/Y8+7+h2xybdZhs/7KWodVhMBfJF1sZhea2ShJ/ybplQr6aMrMzswOzsjMzpT0G0k705+qxCuSFmfPF0vaWGEvP3P8P1fmGlW4Ds3MJK2VtMvdn2wo1WIdDtZfWeuw9LMDkpSd6nhK0i8kPefuq0pvYhBm9ksN/PaXpFMl/b7q/szsBUkLJE2QdFDSg5L+JOllSVMk7ZN0g7tXcnBukP4WaGAz1iX1SLqtYf+77P7mSXpL0oeS+rPJ92lgv7vydZjo70aVsA4rCQEA9cGBQSA4QgAIjhAAgiMEgOAIASC4SkOgxkNyJdFfUXXur869SeX2V/WWQK1/EKK/ourcX517k0rsr+oQAFCxQoOFzOwySU9rYOTf/7j74znvZ2QSUBF3t2bTRxwCI7k4CCEAVGewECiyO8DFQYCTQJEQOBEuDgIgx6ntXkB2qqPuR2KBsIqEwJAuDuLuayStkTgmANRRkd2BWl8cBMDQjHhLwN1/MLM7JP1Zf784yEct6wxAKUq9qAi7A0B12nGKEMBJgBAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgmv7bcgwdPPnz0/W77rrrmT9qquuKrT89evXJ+s7duxI1rdt25asb968edg9of3YEgCCIwSA4AgBIDhCAAiOEACCIwSA4AgBIDhuTV4jq1evTtbzxgmU+bNs5ujRo8n6ihUrkvW9e/cm65s2bRp2T/i7wW5NXmiwkJn1SDoi6ZikH9y9s8j8AJSvFSMG/9ndv2zBfABUgGMCQHBFQ8AlvWZm75lZVysaAlCuorsD89z9gJn9g6TXzewTd3+z8Q1ZOBAQQE0V2hJw9wPZY5+kP0qa0+Q9a9y9k4OGQD2NOATM7EwzG3P8uaTfSNrZqsYAlGPE4wTM7Jca+O0vDexW/N7dV+V8JvQ4gTlzfrah9CMbNmxI1idNmpSsVz1OwKzpaei/yevvyJEjyfrbb7+drK9cuTJZf+edd5L1k13Lxwm4+18l/eOIOwJQC5wiBIIjBIDgCAEgOEIACI4QAIIjBIDguJ5AC02bNi1Zf+2115L18847L1nPOw9/4MCBZH3ChAnJ+qhRo5L1PEXHCbTb8uXLk/Xu7u5k/dixYy3spnyDjRNgSwAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAYJ9BCc+fOTda3bNlSaP555+GnTJmSrF966aXJ+rnnnjvsnlopr/8777yz0Pzz1t+zzz6brD/22GPJ+r59+4bdU5kYJwCgKUIACI4QAIIjBIDgCAEgOEIACI4QAIJjnEAL5V0X/5JLLik0/2uvvTZZ37hxY6H5V23q1KnJ+r333pusL1myJFk/5ZT077z+/v5kPe/nmzcOo2qMEwDQFCEABEcIAMERAkBwhAAQHCEABEcIAMGN+NbkEV155ZXJ+syZM5P1vDEZK1euTNZP9HEAeXp6epL122+/PVnfvn17sv7MM88k63k/n/HjxyfrefeN2L9/f7JeldwtATN7zsz6zGxnw7RxZva6me3OHse2t00A7TKU3YHfSbrsJ9PukfSGu18s6Y3sNYATUG4IuPubkg79ZPJCSeuy5+skLWptWwDKMtIDgxPdvTd7/oWkiS3qB0DJCh8YdHdPfTHIzLokdRVdDoD2GOmWwEEz65Ck7LFvsDe6+xp373T3zhEuC0AbjTQEXpG0OHu+WNLJfe4KOInl7g6Y2QuSFkiaYGb7JT0o6XFJL5vZf0jaJ+mGdjZZF3fffXeyPmrUqELzP3z4cKHPn+yOHTuWrHd3dyfr06ZNS9aXLl1a6PPPP/98sj5//vxkvSq5IeDuNw5S+nWLewFQAYYNA8ERAkBwhAAQHCEABEcIAMERAkBw3HdgGPLuPz958uRkfe/evcn6FVdckazv2bMnWUda3nn+LVu2JOvjxo1L1j/77LNk/cILL0zW2437DgBoihAAgiMEgOAIASA4QgAIjhAAgiMEgOC470CDvO97n3322YXmf//99yfrjANor08//TRZf/HFF5P1vPsenKjYEgCCIwSA4AgBIDhCAAiOEACCIwSA4AgBIDjGCTSYPXt2sj5mzJhk/fPPP0/Wd+/ePeyeUB6zpl+3H3J9ypQpyfry5cuT9aeeeipZbxe2BIDgCAEgOEIACI4QAIIjBIDgCAEgOEIACI5xAg1mzJiRrOfdo6GnpydZ/+CDD4bbEkp09dVXJ+tl3qOjTLlbAmb2nJn1mdnOhmkPmdkBM9ue/bm8vW0CaJeh7A78TtJlTab/t7vPzP78b2vbAlCW3BBw9zclHSqhFwAVKHJg8A4z25HtLoxtWUcASjXSEOiWdJGkmZJ6JT0x2BvNrMvMtprZ1hEuC0AbjSgE3P2gux9z935Jz0qak3jvGnfvdPfOkTYJoH1GFAJm1tHw8hpJOwd7L4B6yx0nYGYvSFogaYKZ7Zf0oKQFZjZTkkvqkXRb+1oszy233JKsn6znidEafX19yfpLL71UUifDkxsC7n5jk8lr29ALgAowbBgIjhAAgiMEgOAIASA4QgAIjhAAguN6Ag3Wr1+frN98883J+umnn56sn3HGGcn6N998k6yjmJtuuilZHzduXKH5540T6O3tLTT/dmFLAAiOEACCIwSA4AgBIDhCAAiOEACCIwSA4Bgn0GDHjh2FPj979uxkvbu7O1lfvHhxoeVHt3DhwmR93bp1yXrR+0pcd911yXpdsSUABEcIAMERAkBwhAAQHCEABEcIAMERAkBwjBMYBjMr9Pm877OPGTMmWX/66aeT9c2bNw+7pzqZNGlSst7V1ZWsP/DAA8n6Kaekf+f19/cn63n3DdizZ0+yXldsCQDBEQJAcIQAEBwhAARHCADBEQJAcIQAEJzlfYe6pQszK29hIzB69OhkfdeuXcl6R0dHK9v5maNHjybrK1asSNYPHz6crH/77bfJ+quvvpqsX3/99cn6jBkzkvUlS5Yk6+ecc06ynidvnMejjz6arK9atSpZ//7774fdU5ncvekKyN0SMLPzzWyTmX1sZh+Z2bJs+jgze93MdmePY1vdNID2G8ruwA+SVrj7ryTNlfRbM/uVpHskveHuF0t6I3sN4ASTGwLu3uvu27LnRyTtkjRZ0kJJx6/XtE7Sojb1CKCNhnVg0MymSpol6V1JE939+M3VvpA0sbWtASjDkL9AZGajJW2QtNzdv2o8yOLuPthBPzPrkpT+5geAygxpS8DMTtNAADzv7n/IJh80s46s3iGp6S1Z3X2Nu3e6e2crGgbQWkM5O2CS1kra5e5PNpRekXT8GtmLJW1sfXsA2i13nICZzZP0lqQPJR3/wvV9Gjgu8LKkKZL2SbrB3Q/lzKvW4wTy3Hrrrcn6smXLkvXp06cXWn7eee6iYz7yznO///77yfrcuXOT9XaPScm7L0De9QAefvjhZL3u4wDyDDZOIPeYgLtvkTTYv75fF2kKQPUYNgwERwgAwRECQHCEABAcIQAERwgAwXE9gRYaP358sr5o0aJkffXq1cn6WWedlayX+bNspug4hu+++y5Z7+trOij1b/KuB7B27dpk/WQ34usJADi5EQJAcIQAEBwhAARHCADBEQJAcIQAEBzjBGpk/vz5yfqsWbMKzX/p0qXJ+gUXXFBo/nnjBB555JFk/ZNPPknW864HgDTGCQBoihAAgiMEgOAIASA4QgAIjhAAgiMEgOAYJwAEwTgBAE0RAkBwhAAQHCEABEcIAMERAkBwhAAQXG4ImNn5ZrbJzD42s4/MbFk2/SEzO2Bm27M/l7e/XQCtljtYyMw6JHW4+zYzGyPpPUmLJN0g6Wt3T98x48fzYrAQUJHBBgudOoQP9krqzZ4fMbNdkia3tj0AVRnWMQEzmypplqR3s0l3mNkOM3vOzMa2ujkA7TfkEDCz0ZI2SFru7l9J6pZ0kaSZGthSeGKQz3WZ2VYz21q8XQCtNqQvEJnZaZJelfRnd3+ySX2qpFfdfXrOfDgmAFRkxF8gsoFLyK6VtKsxALIDhsddI2ln0SYBlG8oZwfmSXpL0oeS+rPJ90m6UQO7Ai6pR9Jt2UHE1LzYEgAqMtiWANcTAILgegIAmiIEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASA4QgAIjhAAgiMEgOAIASC43KsNt9iXkvY1vJ6QTasr+iumzv3VuTep9f1dMFih1IuK/GzhZlvdvbOyBnLQXzF17q/OvUnl9sfuABAcIQAEV3UIrKl4+Xnor5g691fn3qQS+6v0mACA6lW9JQCgYoQAEBwhAARHCADBEQJAcP8PhdR+EaqqBnsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_and_label_train_X(i):\n",
    "    print(\"Label:\", train_y[i])\n",
    "    print(\"Y onehot:\", train_y_onehot.T[i])\n",
    "    plt.gray()\n",
    "    plt.matshow(train_X[i])\n",
    "    plt.show()\n",
    "\n",
    "    # p = np.reshape(train_X_flatten.T[i].T,(28,28))\n",
    "    # plt.gray()\n",
    "    # plt.matshow(p)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_and_label_train_X(np.random.randint(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "171c311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3653d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "#np.warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# init params\n",
    "W1 = np.random.uniform(-0.5, 0.5, (10,784))\n",
    "b1 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "W2 = np.random.uniform(-0.5, 0.5, (10,10))\n",
    "b2 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "\n",
    "i = 0\n",
    "m = 2\n",
    "\n",
    "X = train_X_flatten.T[i:i+m].T # shape -> 784, m\n",
    "Y = train_y_onehot.T[i:i+m].T\n",
    "\n",
    "# forward prop\n",
    "Z1 = W1@X+b1\n",
    "A1 = ReLU(Z1)\n",
    "Z2 = W2@A1+b2\n",
    "A2 = softmax(Z2)\n",
    "\n",
    "# backward prop\n",
    "dZ2 = A2-Y\n",
    "dW2 = 1/m*dZ2@A1.T\n",
    "db2 = 1/m*np.sum(dZ2)\n",
    "dZ1 = W2.T@dZ2 * ReLU_deriv(Z1)\n",
    "dW1 = 1/m*dZ1@X.T\n",
    "db1 = 1/m*np.sum(dZ1)\n",
    "\n",
    "# update poram\n",
    "learning_rate = 0.2\n",
    "W1 = W1 - learning_rate * dW1\n",
    "b1 = b1 - learning_rate * db1    \n",
    "W2 = W2 - learning_rate * dW2  \n",
    "b2 = b2 - learning_rate * db2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8438d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    # print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e09b3e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (10, 60000) (784, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape ,train_y_onehot.shape, train_X_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "090efcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "0.09476666666666667\n",
      "Iteration:  10\n",
      "0.15378333333333333\n",
      "Iteration:  20\n",
      "0.20518333333333333\n",
      "Iteration:  30\n",
      "0.2767833333333333\n",
      "Iteration:  40\n",
      "0.34723333333333334\n",
      "Iteration:  50\n",
      "0.40446666666666664\n",
      "Iteration:  60\n",
      "0.46623333333333333\n",
      "Iteration:  70\n",
      "0.5129333333333334\n",
      "Iteration:  80\n",
      "0.54725\n",
      "Iteration:  90\n",
      "0.5746\n",
      "Iteration:  100\n",
      "0.5983666666666667\n",
      "Iteration:  110\n",
      "0.6204833333333334\n",
      "Iteration:  120\n",
      "0.6427666666666667\n",
      "Iteration:  130\n",
      "0.6624833333333333\n",
      "Iteration:  140\n",
      "0.6787833333333333\n",
      "Iteration:  150\n",
      "0.6929\n",
      "Iteration:  160\n",
      "0.7055666666666667\n",
      "Iteration:  170\n",
      "0.7163666666666667\n",
      "Iteration:  180\n",
      "0.7268333333333333\n",
      "Iteration:  190\n",
      "0.7363\n",
      "Iteration:  200\n",
      "0.7446333333333334\n",
      "Iteration:  210\n",
      "0.75235\n",
      "Iteration:  220\n",
      "0.7593833333333333\n",
      "Iteration:  230\n",
      "0.7659833333333333\n",
      "Iteration:  240\n",
      "0.7720166666666667\n",
      "Iteration:  250\n",
      "0.7772666666666667\n",
      "Iteration:  260\n",
      "0.78255\n",
      "Iteration:  270\n",
      "0.78735\n",
      "Iteration:  280\n",
      "0.7917666666666666\n",
      "Iteration:  290\n",
      "0.7954\n",
      "Iteration:  300\n",
      "0.7988666666666666\n",
      "Iteration:  310\n",
      "0.8021833333333334\n",
      "Iteration:  320\n",
      "0.80515\n",
      "Iteration:  330\n",
      "0.80835\n",
      "Iteration:  340\n",
      "0.8110333333333334\n",
      "Iteration:  350\n",
      "0.8138333333333333\n",
      "Iteration:  360\n",
      "0.8164833333333333\n",
      "Iteration:  370\n",
      "0.8187\n",
      "Iteration:  380\n",
      "0.82085\n",
      "Iteration:  390\n",
      "0.8229833333333333\n",
      "Iteration:  400\n",
      "0.8249833333333333\n",
      "Iteration:  410\n",
      "0.8267166666666667\n",
      "Iteration:  420\n",
      "0.8289666666666666\n",
      "Iteration:  430\n",
      "0.8310333333333333\n",
      "Iteration:  440\n",
      "0.8330833333333333\n",
      "Iteration:  450\n",
      "0.8345666666666667\n",
      "Iteration:  460\n",
      "0.8361666666666666\n",
      "Iteration:  470\n",
      "0.8375166666666667\n",
      "Iteration:  480\n",
      "0.8387166666666667\n",
      "Iteration:  490\n",
      "0.8399666666666666\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.uniform(-0.5, 0.5, (10,784))\n",
    "b1 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "W2 = np.random.uniform(-0.5, 0.5, (10,10))\n",
    "b2 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "iterations = 500\n",
    "\n",
    "X = train_X_flatten # shape -> 784, m\n",
    "Y = train_y_onehot\n",
    "m = 60000\n",
    "\n",
    "correct_predictions = 0\n",
    "wrong_predictions = 0\n",
    "\n",
    "for iter in range(iterations):\n",
    "    # forward prop\n",
    "    Z1 = W1@X+b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2@A1+b2\n",
    "    A2 = softmax(Z2)\n",
    "\n",
    "    # backward prop\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = 1/m*dZ2@A1.T\n",
    "    db2 = 1/m*np.sum(dZ2)\n",
    "    dZ1 = W2.T@dZ2 * ReLU_deriv(Z1)\n",
    "    dW1 = 1/m*dZ1@X.T\n",
    "    db1 = 1/m*np.sum(dZ1)\n",
    "\n",
    "    # update poram\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1    \n",
    "    W2 = W2 - learning_rate * dW2  \n",
    "    b2 = b2 - learning_rate * db2    \n",
    "\n",
    "    # accuracy\n",
    "    if iter % 10 == 0 :\n",
    "        # print(A2)\n",
    "        print(\"Iteration: \", iter)\n",
    "        predictions = get_predictions(A2)\n",
    "        print(get_accuracy(predictions, train_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7a9afcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = train_X_flatten.T[0:5000].T.shape\n",
    "X\n",
    "iterations = train_X_flatten.T.shape[0]/batch_size\n",
    "iterations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45804572",
   "metadata": {},
   "source": [
    "## IMPLEMENTING EPOCH? BUT I DON'T KNOW HOW WOULD IT HELP? WHY NOT JUST USE ALL THE DATA AT ONCE\n",
    "\n",
    "Decreasing the batch size during training of a neural network can have several potential benefits:\n",
    "\n",
    "1- Reducing memory requirements: A smaller batch size means that fewer training examples are processed in each iteration, which can reduce the amount of memory required to store the training data and intermediate results. This can be important for training larger neural networks or when working with limited memory resources.\n",
    "\n",
    "2- More frequent weight updates: A smaller batch size means that the neural network is updated more frequently during each epoch, which can help to speed up the training process and potentially lead to better convergence. With a larger batch size, the weight updates are less frequent, and the optimizer may take longer to converge to the optimal weights.\n",
    "\n",
    "3- Improved generalization: Smaller batches can help to prevent the neural network from overfitting to the training data by introducing more randomness and variation into the training process. This can help the network to generalize better to new data and improve its performance on the validation and test sets.\n",
    "\n",
    "However, decreasing the batch size may also have some potential drawbacks:\n",
    "\n",
    "1- Slower training convergence: With smaller batch sizes, the optimization process may require more iterations or epochs to converge to the optimal weights, which can result in longer training times.\n",
    "\n",
    "2- Noisier weight updates: With smaller batch sizes, the gradient estimates may be noisier and less accurate, which can lead to more unstable training and slower convergence. This can be mitigated by using techniques such as momentum or weight decay.\n",
    "\n",
    "3- Overall, the optimal batch size will depend on the specific neural network architecture, dataset, and optimization algorithm used, and it may require experimentation and tuning to find the best value.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6147b2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_X_flatten.T.shape[0]//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c8ff9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Iteration: 0\n",
      "0.11436666666666667\n",
      "Epoch: 1  Iteration: 0\n",
      "0.12951666666666667\n",
      "Epoch: 2  Iteration: 0\n",
      "0.13766666666666666\n",
      "Epoch: 3  Iteration: 0\n",
      "0.14471666666666666\n",
      "Epoch: 4  Iteration: 0\n",
      "0.15291666666666667\n",
      "Epoch: 5  Iteration: 0\n",
      "0.1589\n",
      "Epoch: 6  Iteration: 0\n",
      "0.1662\n",
      "Epoch: 7  Iteration: 0\n",
      "0.17438333333333333\n",
      "Epoch: 8  Iteration: 0\n",
      "0.18336666666666668\n",
      "Epoch: 9  Iteration: 0\n",
      "0.19521666666666668\n",
      "Epoch: 10  Iteration: 0\n",
      "0.2063\n",
      "Epoch: 11  Iteration: 0\n",
      "0.21646666666666667\n",
      "Epoch: 12  Iteration: 0\n",
      "0.22673333333333334\n",
      "Epoch: 13  Iteration: 0\n",
      "0.23643333333333333\n",
      "Epoch: 14  Iteration: 0\n",
      "0.24606666666666666\n",
      "Epoch: 15  Iteration: 0\n",
      "0.2543\n",
      "Epoch: 16  Iteration: 0\n",
      "0.26271666666666665\n",
      "Epoch: 17  Iteration: 0\n",
      "0.2702333333333333\n",
      "Epoch: 18  Iteration: 0\n",
      "0.2768333333333333\n",
      "Epoch: 19  Iteration: 0\n",
      "0.2831166666666667\n",
      "Epoch: 20  Iteration: 0\n",
      "0.28995\n",
      "Epoch: 21  Iteration: 0\n",
      "0.2966666666666667\n",
      "Epoch: 22  Iteration: 0\n",
      "0.3022666666666667\n",
      "Epoch: 23  Iteration: 0\n",
      "0.3093\n",
      "Epoch: 24  Iteration: 0\n",
      "0.31535\n",
      "Epoch: 25  Iteration: 0\n",
      "0.32211666666666666\n",
      "Epoch: 26  Iteration: 0\n",
      "0.3279\n",
      "Epoch: 27  Iteration: 0\n",
      "0.33363333333333334\n",
      "Epoch: 28  Iteration: 0\n",
      "0.33986666666666665\n",
      "Epoch: 29  Iteration: 0\n",
      "0.3453333333333333\n",
      "Epoch: 30  Iteration: 0\n",
      "0.35155\n",
      "Epoch: 31  Iteration: 0\n",
      "0.3565\n",
      "Epoch: 32  Iteration: 0\n",
      "0.36175\n",
      "Epoch: 33  Iteration: 0\n",
      "0.3670333333333333\n",
      "Epoch: 34  Iteration: 0\n",
      "0.3716833333333333\n",
      "Epoch: 35  Iteration: 0\n",
      "0.37653333333333333\n",
      "Epoch: 36  Iteration: 0\n",
      "0.3814\n",
      "Epoch: 37  Iteration: 0\n",
      "0.38585\n",
      "Epoch: 38  Iteration: 0\n",
      "0.3908333333333333\n",
      "Epoch: 39  Iteration: 0\n",
      "0.3958333333333333\n",
      "Epoch: 40  Iteration: 0\n",
      "0.40023333333333333\n",
      "Epoch: 41  Iteration: 0\n",
      "0.40463333333333334\n",
      "Epoch: 42  Iteration: 0\n",
      "0.40908333333333335\n",
      "Epoch: 43  Iteration: 0\n",
      "0.41333333333333333\n",
      "Epoch: 44  Iteration: 0\n",
      "0.41733333333333333\n",
      "Epoch: 45  Iteration: 0\n",
      "0.42195\n",
      "Epoch: 46  Iteration: 0\n",
      "0.4259\n",
      "Epoch: 47  Iteration: 0\n",
      "0.43046666666666666\n",
      "Epoch: 48  Iteration: 0\n",
      "0.4340833333333333\n",
      "Epoch: 49  Iteration: 0\n",
      "0.43778333333333336\n",
      "Epoch: 50  Iteration: 0\n",
      "0.44185\n",
      "Epoch: 51  Iteration: 0\n",
      "0.4460166666666667\n",
      "Epoch: 52  Iteration: 0\n",
      "0.45016666666666666\n",
      "Epoch: 53  Iteration: 0\n",
      "0.4537\n",
      "Epoch: 54  Iteration: 0\n",
      "0.4575166666666667\n",
      "Epoch: 55  Iteration: 0\n",
      "0.46123333333333333\n",
      "Epoch: 56  Iteration: 0\n",
      "0.4644\n",
      "Epoch: 57  Iteration: 0\n",
      "0.46776666666666666\n",
      "Epoch: 58  Iteration: 0\n",
      "0.47128333333333333\n",
      "Epoch: 59  Iteration: 0\n",
      "0.47451666666666664\n",
      "Epoch: 60  Iteration: 0\n",
      "0.4783\n",
      "Epoch: 61  Iteration: 0\n",
      "0.48168333333333335\n",
      "Epoch: 62  Iteration: 0\n",
      "0.48468333333333335\n",
      "Epoch: 63  Iteration: 0\n",
      "0.48806666666666665\n",
      "Epoch: 64  Iteration: 0\n",
      "0.4919\n",
      "Epoch: 65  Iteration: 0\n",
      "0.4951\n",
      "Epoch: 66  Iteration: 0\n",
      "0.49856666666666666\n",
      "Epoch: 67  Iteration: 0\n",
      "0.5021833333333333\n",
      "Epoch: 68  Iteration: 0\n",
      "0.5054333333333333\n",
      "Epoch: 69  Iteration: 0\n",
      "0.5097\n",
      "Epoch: 70  Iteration: 0\n",
      "0.5137833333333334\n",
      "Epoch: 71  Iteration: 0\n",
      "0.5175333333333333\n",
      "Epoch: 72  Iteration: 0\n",
      "0.5213\n",
      "Epoch: 73  Iteration: 0\n",
      "0.5253\n",
      "Epoch: 74  Iteration: 0\n",
      "0.5294333333333333\n",
      "Epoch: 75  Iteration: 0\n",
      "0.5335333333333333\n",
      "Epoch: 76  Iteration: 0\n",
      "0.5377666666666666\n",
      "Epoch: 77  Iteration: 0\n",
      "0.5419333333333334\n",
      "Epoch: 78  Iteration: 0\n",
      "0.5461833333333334\n",
      "Epoch: 79  Iteration: 0\n",
      "0.5500833333333334\n",
      "Epoch: 80  Iteration: 0\n",
      "0.5545\n",
      "Epoch: 81  Iteration: 0\n",
      "0.55865\n",
      "Epoch: 82  Iteration: 0\n",
      "0.5632666666666667\n",
      "Epoch: 83  Iteration: 0\n",
      "0.5676\n",
      "Epoch: 84  Iteration: 0\n",
      "0.5721833333333334\n",
      "Epoch: 85  Iteration: 0\n",
      "0.5765833333333333\n",
      "Epoch: 86  Iteration: 0\n",
      "0.58095\n",
      "Epoch: 87  Iteration: 0\n",
      "0.5847\n",
      "Epoch: 88  Iteration: 0\n",
      "0.58885\n",
      "Epoch: 89  Iteration: 0\n",
      "0.5934666666666667\n",
      "Epoch: 90  Iteration: 0\n",
      "0.5979\n",
      "Epoch: 91  Iteration: 0\n",
      "0.6014166666666667\n",
      "Epoch: 92  Iteration: 0\n",
      "0.6046833333333334\n",
      "Epoch: 93  Iteration: 0\n",
      "0.6083\n",
      "Epoch: 94  Iteration: 0\n",
      "0.6118833333333333\n",
      "Epoch: 95  Iteration: 0\n",
      "0.6149333333333333\n",
      "Epoch: 96  Iteration: 0\n",
      "0.61845\n",
      "Epoch: 97  Iteration: 0\n",
      "0.6216\n",
      "Epoch: 98  Iteration: 0\n",
      "0.6247\n",
      "Epoch: 99  Iteration: 0\n",
      "0.6277666666666667\n",
      "Epoch: 100  Iteration: 0\n",
      "0.6304333333333333\n",
      "Epoch: 101  Iteration: 0\n",
      "0.6336166666666667\n",
      "Epoch: 102  Iteration: 0\n",
      "0.6362166666666667\n",
      "Epoch: 103  Iteration: 0\n",
      "0.6388333333333334\n",
      "Epoch: 104  Iteration: 0\n",
      "0.6419166666666667\n",
      "Epoch: 105  Iteration: 0\n",
      "0.6445333333333333\n",
      "Epoch: 106  Iteration: 0\n",
      "0.64705\n",
      "Epoch: 107  Iteration: 0\n",
      "0.6496666666666666\n",
      "Epoch: 108  Iteration: 0\n",
      "0.6521166666666667\n",
      "Epoch: 109  Iteration: 0\n",
      "0.6544\n",
      "Epoch: 110  Iteration: 0\n",
      "0.6569833333333334\n",
      "Epoch: 111  Iteration: 0\n",
      "0.6596\n",
      "Epoch: 112  Iteration: 0\n",
      "0.6618666666666667\n",
      "Epoch: 113  Iteration: 0\n",
      "0.6639166666666667\n",
      "Epoch: 114  Iteration: 0\n",
      "0.6659166666666667\n",
      "Epoch: 115  Iteration: 0\n",
      "0.6678\n",
      "Epoch: 116  Iteration: 0\n",
      "0.6698833333333334\n",
      "Epoch: 117  Iteration: 0\n",
      "0.6719666666666667\n",
      "Epoch: 118  Iteration: 0\n",
      "0.6741333333333334\n",
      "Epoch: 119  Iteration: 0\n",
      "0.6762166666666667\n",
      "Epoch: 120  Iteration: 0\n",
      "0.6779166666666666\n",
      "Epoch: 121  Iteration: 0\n",
      "0.6798833333333333\n",
      "Epoch: 122  Iteration: 0\n",
      "0.6816333333333333\n",
      "Epoch: 123  Iteration: 0\n",
      "0.6837166666666666\n",
      "Epoch: 124  Iteration: 0\n",
      "0.6852166666666667\n",
      "Epoch: 125  Iteration: 0\n",
      "0.6867833333333333\n",
      "Epoch: 126  Iteration: 0\n",
      "0.6888166666666666\n",
      "Epoch: 127  Iteration: 0\n",
      "0.6906333333333333\n",
      "Epoch: 128  Iteration: 0\n",
      "0.6925833333333333\n",
      "Epoch: 129  Iteration: 0\n",
      "0.6945166666666667\n",
      "Epoch: 130  Iteration: 0\n",
      "0.6961833333333334\n",
      "Epoch: 131  Iteration: 0\n",
      "0.6978\n",
      "Epoch: 132  Iteration: 0\n",
      "0.69945\n",
      "Epoch: 133  Iteration: 0\n",
      "0.7010166666666666\n",
      "Epoch: 134  Iteration: 0\n",
      "0.7027166666666667\n",
      "Epoch: 135  Iteration: 0\n",
      "0.7046166666666667\n",
      "Epoch: 136  Iteration: 0\n",
      "0.7059666666666666\n",
      "Epoch: 137  Iteration: 0\n",
      "0.7075666666666667\n",
      "Epoch: 138  Iteration: 0\n",
      "0.7088333333333333\n",
      "Epoch: 139  Iteration: 0\n",
      "0.7102833333333334\n",
      "Epoch: 140  Iteration: 0\n",
      "0.7115666666666667\n",
      "Epoch: 141  Iteration: 0\n",
      "0.7129\n",
      "Epoch: 142  Iteration: 0\n",
      "0.7142833333333334\n",
      "Epoch: 143  Iteration: 0\n",
      "0.7155833333333333\n",
      "Epoch: 144  Iteration: 0\n",
      "0.7170333333333333\n",
      "Epoch: 145  Iteration: 0\n",
      "0.7188333333333333\n",
      "Epoch: 146  Iteration: 0\n",
      "0.7202833333333334\n",
      "Epoch: 147  Iteration: 0\n",
      "0.7218166666666667\n",
      "Epoch: 148  Iteration: 0\n",
      "0.7232\n",
      "Epoch: 149  Iteration: 0\n",
      "0.72465\n",
      "Epoch: 150  Iteration: 0\n",
      "0.7254666666666667\n",
      "Epoch: 151  Iteration: 0\n",
      "0.7268666666666667\n",
      "Epoch: 152  Iteration: 0\n",
      "0.72765\n",
      "Epoch: 153  Iteration: 0\n",
      "0.72895\n",
      "Epoch: 154  Iteration: 0\n",
      "0.7299833333333333\n",
      "Epoch: 155  Iteration: 0\n",
      "0.7313333333333333\n",
      "Epoch: 156  Iteration: 0\n",
      "0.73235\n",
      "Epoch: 157  Iteration: 0\n",
      "0.7335666666666667\n",
      "Epoch: 158  Iteration: 0\n",
      "0.73455\n",
      "Epoch: 159  Iteration: 0\n",
      "0.7353833333333334\n",
      "Epoch: 160  Iteration: 0\n",
      "0.7365333333333334\n",
      "Epoch: 161  Iteration: 0\n",
      "0.7373833333333333\n",
      "Epoch: 162  Iteration: 0\n",
      "0.7386666666666667\n",
      "Epoch: 163  Iteration: 0\n",
      "0.7397\n",
      "Epoch: 164  Iteration: 0\n",
      "0.7407\n",
      "Epoch: 165  Iteration: 0\n",
      "0.7416333333333334\n",
      "Epoch: 166  Iteration: 0\n",
      "0.7426666666666667\n",
      "Epoch: 167  Iteration: 0\n",
      "0.7437166666666667\n",
      "Epoch: 168  Iteration: 0\n",
      "0.7446333333333334\n",
      "Epoch: 169  Iteration: 0\n",
      "0.74545\n",
      "Epoch: 170  Iteration: 0\n",
      "0.7464666666666666\n",
      "Epoch: 171  Iteration: 0\n",
      "0.7474666666666666\n",
      "Epoch: 172  Iteration: 0\n",
      "0.7484166666666666\n",
      "Epoch: 173  Iteration: 0\n",
      "0.7492666666666666\n",
      "Epoch: 174  Iteration: 0\n",
      "0.7500666666666667\n",
      "Epoch: 175  Iteration: 0\n",
      "0.7508666666666667\n",
      "Epoch: 176  Iteration: 0\n",
      "0.7517166666666667\n",
      "Epoch: 177  Iteration: 0\n",
      "0.7523\n",
      "Epoch: 178  Iteration: 0\n",
      "0.7529833333333333\n",
      "Epoch: 179  Iteration: 0\n",
      "0.75365\n",
      "Epoch: 180  Iteration: 0\n",
      "0.7546666666666667\n",
      "Epoch: 181  Iteration: 0\n",
      "0.7555333333333333\n",
      "Epoch: 182  Iteration: 0\n",
      "0.7562833333333333\n",
      "Epoch: 183  Iteration: 0\n",
      "0.757\n",
      "Epoch: 184  Iteration: 0\n",
      "0.7577833333333334\n",
      "Epoch: 185  Iteration: 0\n",
      "0.7584666666666666\n",
      "Epoch: 186  Iteration: 0\n",
      "0.7592666666666666\n",
      "Epoch: 187  Iteration: 0\n",
      "0.76005\n",
      "Epoch: 188  Iteration: 0\n",
      "0.7607333333333334\n",
      "Epoch: 189  Iteration: 0\n",
      "0.7613333333333333\n",
      "Epoch: 190  Iteration: 0\n",
      "0.7619666666666667\n",
      "Epoch: 191  Iteration: 0\n",
      "0.7627833333333334\n",
      "Epoch: 192  Iteration: 0\n",
      "0.7636\n",
      "Epoch: 193  Iteration: 0\n",
      "0.7645833333333333\n",
      "Epoch: 194  Iteration: 0\n",
      "0.7654833333333333\n",
      "Epoch: 195  Iteration: 0\n",
      "0.7660833333333333\n",
      "Epoch: 196  Iteration: 0\n",
      "0.7664833333333333\n",
      "Epoch: 197  Iteration: 0\n",
      "0.7672\n",
      "Epoch: 198  Iteration: 0\n",
      "0.7677833333333334\n",
      "Epoch: 199  Iteration: 0\n",
      "0.7687166666666667\n",
      "Epoch: 200  Iteration: 0\n",
      "0.7693\n",
      "Epoch: 201  Iteration: 0\n",
      "0.7699\n",
      "Epoch: 202  Iteration: 0\n",
      "0.7705833333333333\n",
      "Epoch: 203  Iteration: 0\n",
      "0.7713333333333333\n",
      "Epoch: 204  Iteration: 0\n",
      "0.7718833333333334\n",
      "Epoch: 205  Iteration: 0\n",
      "0.7727166666666667\n",
      "Epoch: 206  Iteration: 0\n",
      "0.7733\n",
      "Epoch: 207  Iteration: 0\n",
      "0.7740333333333334\n",
      "Epoch: 208  Iteration: 0\n",
      "0.7746166666666666\n",
      "Epoch: 209  Iteration: 0\n",
      "0.7752666666666667\n",
      "Epoch: 210  Iteration: 0\n",
      "0.7760333333333334\n",
      "Epoch: 211  Iteration: 0\n",
      "0.7764\n",
      "Epoch: 212  Iteration: 0\n",
      "0.77695\n",
      "Epoch: 213  Iteration: 0\n",
      "0.7776166666666666\n",
      "Epoch: 214  Iteration: 0\n",
      "0.7783\n",
      "Epoch: 215  Iteration: 0\n",
      "0.7789166666666667\n",
      "Epoch: 216  Iteration: 0\n",
      "0.7795666666666666\n",
      "Epoch: 217  Iteration: 0\n",
      "0.7802666666666667\n",
      "Epoch: 218  Iteration: 0\n",
      "0.78105\n",
      "Epoch: 219  Iteration: 0\n",
      "0.7816333333333333\n",
      "Epoch: 220  Iteration: 0\n",
      "0.7822\n",
      "Epoch: 221  Iteration: 0\n",
      "0.78275\n",
      "Epoch: 222  Iteration: 0\n",
      "0.78315\n",
      "Epoch: 223  Iteration: 0\n",
      "0.7839166666666667\n",
      "Epoch: 224  Iteration: 0\n",
      "0.7845666666666666\n",
      "Epoch: 225  Iteration: 0\n",
      "0.7850333333333334\n",
      "Epoch: 226  Iteration: 0\n",
      "0.7857\n",
      "Epoch: 227  Iteration: 0\n",
      "0.7862666666666667\n",
      "Epoch: 228  Iteration: 0\n",
      "0.78695\n",
      "Epoch: 229  Iteration: 0\n",
      "0.7875333333333333\n",
      "Epoch: 230  Iteration: 0\n",
      "0.78795\n",
      "Epoch: 231  Iteration: 0\n",
      "0.7885833333333333\n",
      "Epoch: 232  Iteration: 0\n",
      "0.78925\n",
      "Epoch: 233  Iteration: 0\n",
      "0.7897333333333333\n",
      "Epoch: 234  Iteration: 0\n",
      "0.7903333333333333\n",
      "Epoch: 235  Iteration: 0\n",
      "0.7907333333333333\n",
      "Epoch: 236  Iteration: 0\n",
      "0.7911166666666667\n",
      "Epoch: 237  Iteration: 0\n",
      "0.7917666666666666\n",
      "Epoch: 238  Iteration: 0\n",
      "0.7922833333333333\n",
      "Epoch: 239  Iteration: 0\n",
      "0.7928666666666667\n",
      "Epoch: 240  Iteration: 0\n",
      "0.7934333333333333\n",
      "Epoch: 241  Iteration: 0\n",
      "0.7939666666666667\n",
      "Epoch: 242  Iteration: 0\n",
      "0.7944166666666667\n",
      "Epoch: 243  Iteration: 0\n",
      "0.7950333333333334\n",
      "Epoch: 244  Iteration: 0\n",
      "0.7954833333333333\n",
      "Epoch: 245  Iteration: 0\n",
      "0.7958\n",
      "Epoch: 246  Iteration: 0\n",
      "0.7964\n",
      "Epoch: 247  Iteration: 0\n",
      "0.7968\n",
      "Epoch: 248  Iteration: 0\n",
      "0.7971833333333334\n",
      "Epoch: 249  Iteration: 0\n",
      "0.7976833333333333\n",
      "Epoch: 250  Iteration: 0\n",
      "0.7980833333333334\n",
      "Epoch: 251  Iteration: 0\n",
      "0.7984666666666667\n",
      "Epoch: 252  Iteration: 0\n",
      "0.7989166666666667\n",
      "Epoch: 253  Iteration: 0\n",
      "0.7993833333333333\n",
      "Epoch: 254  Iteration: 0\n",
      "0.79975\n",
      "Epoch: 255  Iteration: 0\n",
      "0.8002166666666667\n",
      "Epoch: 256  Iteration: 0\n",
      "0.8007666666666666\n",
      "Epoch: 257  Iteration: 0\n",
      "0.8012833333333333\n",
      "Epoch: 258  Iteration: 0\n",
      "0.8014833333333333\n",
      "Epoch: 259  Iteration: 0\n",
      "0.8018833333333333\n",
      "Epoch: 260  Iteration: 0\n",
      "0.80215\n",
      "Epoch: 261  Iteration: 0\n",
      "0.8026166666666666\n",
      "Epoch: 262  Iteration: 0\n",
      "0.8030333333333334\n",
      "Epoch: 263  Iteration: 0\n",
      "0.8035\n",
      "Epoch: 264  Iteration: 0\n",
      "0.8039\n",
      "Epoch: 265  Iteration: 0\n",
      "0.8043\n",
      "Epoch: 266  Iteration: 0\n",
      "0.8045666666666667\n",
      "Epoch: 267  Iteration: 0\n",
      "0.8048666666666666\n",
      "Epoch: 268  Iteration: 0\n",
      "0.8052333333333334\n",
      "Epoch: 269  Iteration: 0\n",
      "0.8056166666666666\n",
      "Epoch: 270  Iteration: 0\n",
      "0.8061166666666667\n",
      "Epoch: 271  Iteration: 0\n",
      "0.8064166666666667\n",
      "Epoch: 272  Iteration: 0\n",
      "0.8069166666666666\n",
      "Epoch: 273  Iteration: 0\n",
      "0.8072666666666667\n",
      "Epoch: 274  Iteration: 0\n",
      "0.8077333333333333\n",
      "Epoch: 275  Iteration: 0\n",
      "0.8081\n",
      "Epoch: 276  Iteration: 0\n",
      "0.8085\n",
      "Epoch: 277  Iteration: 0\n",
      "0.8088833333333333\n",
      "Epoch: 278  Iteration: 0\n",
      "0.8092666666666667\n",
      "Epoch: 279  Iteration: 0\n",
      "0.8096666666666666\n",
      "Epoch: 280  Iteration: 0\n",
      "0.8099166666666666\n",
      "Epoch: 281  Iteration: 0\n",
      "0.8103833333333333\n",
      "Epoch: 282  Iteration: 0\n",
      "0.8107\n",
      "Epoch: 283  Iteration: 0\n",
      "0.8110833333333334\n",
      "Epoch: 284  Iteration: 0\n",
      "0.8114666666666667\n",
      "Epoch: 285  Iteration: 0\n",
      "0.8118166666666666\n",
      "Epoch: 286  Iteration: 0\n",
      "0.81215\n",
      "Epoch: 287  Iteration: 0\n",
      "0.8125666666666667\n",
      "Epoch: 288  Iteration: 0\n",
      "0.8129333333333333\n",
      "Epoch: 289  Iteration: 0\n",
      "0.81325\n",
      "Epoch: 290  Iteration: 0\n",
      "0.8137333333333333\n",
      "Epoch: 291  Iteration: 0\n",
      "0.8140833333333334\n",
      "Epoch: 292  Iteration: 0\n",
      "0.8143333333333334\n",
      "Epoch: 293  Iteration: 0\n",
      "0.8147\n",
      "Epoch: 294  Iteration: 0\n",
      "0.8150333333333334\n",
      "Epoch: 295  Iteration: 0\n",
      "0.8155166666666667\n",
      "Epoch: 296  Iteration: 0\n",
      "0.8158666666666666\n",
      "Epoch: 297  Iteration: 0\n",
      "0.8162166666666667\n",
      "Epoch: 298  Iteration: 0\n",
      "0.81665\n",
      "Epoch: 299  Iteration: 0\n",
      "0.8170333333333333\n",
      "Epoch: 300  Iteration: 0\n",
      "0.8173166666666667\n",
      "Epoch: 301  Iteration: 0\n",
      "0.8175666666666667\n",
      "Epoch: 302  Iteration: 0\n",
      "0.81785\n",
      "Epoch: 303  Iteration: 0\n",
      "0.8182166666666667\n",
      "Epoch: 304  Iteration: 0\n",
      "0.8183666666666667\n",
      "Epoch: 305  Iteration: 0\n",
      "0.81875\n",
      "Epoch: 306  Iteration: 0\n",
      "0.8190333333333333\n",
      "Epoch: 307  Iteration: 0\n",
      "0.8193166666666667\n",
      "Epoch: 308  Iteration: 0\n",
      "0.8195833333333333\n",
      "Epoch: 309  Iteration: 0\n",
      "0.8198666666666666\n",
      "Epoch: 310  Iteration: 0\n",
      "0.8200833333333334\n",
      "Epoch: 311  Iteration: 0\n",
      "0.82035\n",
      "Epoch: 312  Iteration: 0\n",
      "0.8205833333333333\n",
      "Epoch: 313  Iteration: 0\n",
      "0.8208333333333333\n",
      "Epoch: 314  Iteration: 0\n",
      "0.8210166666666666\n",
      "Epoch: 315  Iteration: 0\n",
      "0.8213\n",
      "Epoch: 316  Iteration: 0\n",
      "0.8216666666666667\n",
      "Epoch: 317  Iteration: 0\n",
      "0.8220166666666666\n",
      "Epoch: 318  Iteration: 0\n",
      "0.82235\n",
      "Epoch: 319  Iteration: 0\n",
      "0.8226\n",
      "Epoch: 320  Iteration: 0\n",
      "0.8230333333333333\n",
      "Epoch: 321  Iteration: 0\n",
      "0.8233166666666667\n",
      "Epoch: 322  Iteration: 0\n",
      "0.8236666666666667\n",
      "Epoch: 323  Iteration: 0\n",
      "0.8239333333333333\n",
      "Epoch: 324  Iteration: 0\n",
      "0.8243\n",
      "Epoch: 325  Iteration: 0\n",
      "0.8244666666666667\n",
      "Epoch: 326  Iteration: 0\n",
      "0.82465\n",
      "Epoch: 327  Iteration: 0\n",
      "0.8249666666666666\n",
      "Epoch: 328  Iteration: 0\n",
      "0.8252833333333334\n",
      "Epoch: 329  Iteration: 0\n",
      "0.8256333333333333\n",
      "Epoch: 330  Iteration: 0\n",
      "0.8259\n",
      "Epoch: 331  Iteration: 0\n",
      "0.8261333333333334\n",
      "Epoch: 332  Iteration: 0\n",
      "0.8265166666666667\n",
      "Epoch: 333  Iteration: 0\n",
      "0.8266666666666667\n",
      "Epoch: 334  Iteration: 0\n",
      "0.8269\n",
      "Epoch: 335  Iteration: 0\n",
      "0.8271833333333334\n",
      "Epoch: 336  Iteration: 0\n",
      "0.8274166666666667\n",
      "Epoch: 337  Iteration: 0\n",
      "0.8276833333333333\n",
      "Epoch: 338  Iteration: 0\n",
      "0.8280166666666666\n",
      "Epoch: 339  Iteration: 0\n",
      "0.8282\n",
      "Epoch: 340  Iteration: 0\n",
      "0.8284666666666667\n",
      "Epoch: 341  Iteration: 0\n",
      "0.8287333333333333\n",
      "Epoch: 342  Iteration: 0\n",
      "0.8290166666666666\n",
      "Epoch: 343  Iteration: 0\n",
      "0.82935\n",
      "Epoch: 344  Iteration: 0\n",
      "0.8295666666666667\n",
      "Epoch: 345  Iteration: 0\n",
      "0.8296666666666667\n",
      "Epoch: 346  Iteration: 0\n",
      "0.8299333333333333\n",
      "Epoch: 347  Iteration: 0\n",
      "0.8302666666666667\n",
      "Epoch: 348  Iteration: 0\n",
      "0.8305166666666667\n",
      "Epoch: 349  Iteration: 0\n",
      "0.8307\n",
      "Epoch: 350  Iteration: 0\n",
      "0.8309333333333333\n",
      "Epoch: 351  Iteration: 0\n",
      "0.8312166666666667\n",
      "Epoch: 352  Iteration: 0\n",
      "0.83135\n",
      "Epoch: 353  Iteration: 0\n",
      "0.8315833333333333\n",
      "Epoch: 354  Iteration: 0\n",
      "0.8319\n",
      "Epoch: 355  Iteration: 0\n",
      "0.8321333333333333\n",
      "Epoch: 356  Iteration: 0\n",
      "0.8323833333333334\n",
      "Epoch: 357  Iteration: 0\n",
      "0.8326166666666667\n",
      "Epoch: 358  Iteration: 0\n",
      "0.8328666666666666\n",
      "Epoch: 359  Iteration: 0\n",
      "0.8331\n",
      "Epoch: 360  Iteration: 0\n",
      "0.8332\n",
      "Epoch: 361  Iteration: 0\n",
      "0.8333666666666667\n",
      "Epoch: 362  Iteration: 0\n",
      "0.8336\n",
      "Epoch: 363  Iteration: 0\n",
      "0.8337666666666667\n",
      "Epoch: 364  Iteration: 0\n",
      "0.83405\n",
      "Epoch: 365  Iteration: 0\n",
      "0.8342666666666667\n",
      "Epoch: 366  Iteration: 0\n",
      "0.8344833333333334\n",
      "Epoch: 367  Iteration: 0\n",
      "0.8346833333333333\n",
      "Epoch: 368  Iteration: 0\n",
      "0.8349666666666666\n",
      "Epoch: 369  Iteration: 0\n",
      "0.8351166666666666\n",
      "Epoch: 370  Iteration: 0\n",
      "0.8352833333333334\n",
      "Epoch: 371  Iteration: 0\n",
      "0.8355166666666667\n",
      "Epoch: 372  Iteration: 0\n",
      "0.8357\n",
      "Epoch: 373  Iteration: 0\n",
      "0.8359333333333333\n",
      "Epoch: 374  Iteration: 0\n",
      "0.83615\n",
      "Epoch: 375  Iteration: 0\n",
      "0.8363833333333334\n",
      "Epoch: 376  Iteration: 0\n",
      "0.8365666666666667\n",
      "Epoch: 377  Iteration: 0\n",
      "0.8367666666666667\n",
      "Epoch: 378  Iteration: 0\n",
      "0.8370333333333333\n",
      "Epoch: 379  Iteration: 0\n",
      "0.8371666666666666\n",
      "Epoch: 380  Iteration: 0\n",
      "0.8373666666666667\n",
      "Epoch: 381  Iteration: 0\n",
      "0.8375\n",
      "Epoch: 382  Iteration: 0\n",
      "0.8375833333333333\n",
      "Epoch: 383  Iteration: 0\n",
      "0.8377833333333333\n",
      "Epoch: 384  Iteration: 0\n",
      "0.8379333333333333\n",
      "Epoch: 385  Iteration: 0\n",
      "0.8380666666666666\n",
      "Epoch: 386  Iteration: 0\n",
      "0.8383\n",
      "Epoch: 387  Iteration: 0\n",
      "0.8384833333333334\n",
      "Epoch: 388  Iteration: 0\n",
      "0.8386833333333333\n",
      "Epoch: 389  Iteration: 0\n",
      "0.8388166666666667\n",
      "Epoch: 390  Iteration: 0\n",
      "0.8389833333333333\n",
      "Epoch: 391  Iteration: 0\n",
      "0.8393166666666667\n",
      "Epoch: 392  Iteration: 0\n",
      "0.8395833333333333\n",
      "Epoch: 393  Iteration: 0\n",
      "0.8397333333333333\n",
      "Epoch: 394  Iteration: 0\n",
      "0.8399166666666666\n",
      "Epoch: 395  Iteration: 0\n",
      "0.84005\n",
      "Epoch: 396  Iteration: 0\n",
      "0.8402833333333334\n",
      "Epoch: 397  Iteration: 0\n",
      "0.84045\n",
      "Epoch: 398  Iteration: 0\n",
      "0.8407\n",
      "Epoch: 399  Iteration: 0\n",
      "0.8409833333333333\n",
      "Epoch: 400  Iteration: 0\n",
      "0.8410666666666666\n",
      "Epoch: 401  Iteration: 0\n",
      "0.84115\n",
      "Epoch: 402  Iteration: 0\n",
      "0.84125\n",
      "Epoch: 403  Iteration: 0\n",
      "0.8414166666666667\n",
      "Epoch: 404  Iteration: 0\n",
      "0.8415666666666667\n",
      "Epoch: 405  Iteration: 0\n",
      "0.8417166666666667\n",
      "Epoch: 406  Iteration: 0\n",
      "0.8419\n",
      "Epoch: 407  Iteration: 0\n",
      "0.842\n",
      "Epoch: 408  Iteration: 0\n",
      "0.8421333333333333\n",
      "Epoch: 409  Iteration: 0\n",
      "0.8423\n",
      "Epoch: 410  Iteration: 0\n",
      "0.8424833333333334\n",
      "Epoch: 411  Iteration: 0\n",
      "0.8426166666666667\n",
      "Epoch: 412  Iteration: 0\n",
      "0.8427\n",
      "Epoch: 413  Iteration: 0\n",
      "0.8428666666666667\n",
      "Epoch: 414  Iteration: 0\n",
      "0.84305\n",
      "Epoch: 415  Iteration: 0\n",
      "0.8432666666666667\n",
      "Epoch: 416  Iteration: 0\n",
      "0.8434166666666667\n",
      "Epoch: 417  Iteration: 0\n",
      "0.8435666666666667\n",
      "Epoch: 418  Iteration: 0\n",
      "0.84375\n",
      "Epoch: 419  Iteration: 0\n",
      "0.84395\n",
      "Epoch: 420  Iteration: 0\n",
      "0.8440833333333333\n",
      "Epoch: 421  Iteration: 0\n",
      "0.8441833333333333\n",
      "Epoch: 422  Iteration: 0\n",
      "0.84425\n",
      "Epoch: 423  Iteration: 0\n",
      "0.8443666666666667\n",
      "Epoch: 424  Iteration: 0\n",
      "0.8444666666666667\n",
      "Epoch: 425  Iteration: 0\n",
      "0.84465\n",
      "Epoch: 426  Iteration: 0\n",
      "0.845\n",
      "Epoch: 427  Iteration: 0\n",
      "0.8450833333333333\n",
      "Epoch: 428  Iteration: 0\n",
      "0.8451166666666666\n",
      "Epoch: 429  Iteration: 0\n",
      "0.8453333333333334\n",
      "Epoch: 430  Iteration: 0\n",
      "0.8454\n",
      "Epoch: 431  Iteration: 0\n",
      "0.8456\n",
      "Epoch: 432  Iteration: 0\n",
      "0.8457333333333333\n",
      "Epoch: 433  Iteration: 0\n",
      "0.8459\n",
      "Epoch: 434  Iteration: 0\n",
      "0.84615\n",
      "Epoch: 435  Iteration: 0\n",
      "0.84635\n",
      "Epoch: 436  Iteration: 0\n",
      "0.84645\n",
      "Epoch: 437  Iteration: 0\n",
      "0.8466\n",
      "Epoch: 438  Iteration: 0\n",
      "0.8467\n",
      "Epoch: 439  Iteration: 0\n",
      "0.8468833333333333\n",
      "Epoch: 440  Iteration: 0\n",
      "0.8470833333333333\n",
      "Epoch: 441  Iteration: 0\n",
      "0.8471833333333333\n",
      "Epoch: 442  Iteration: 0\n",
      "0.8473833333333334\n",
      "Epoch: 443  Iteration: 0\n",
      "0.84755\n",
      "Epoch: 444  Iteration: 0\n",
      "0.8477\n",
      "Epoch: 445  Iteration: 0\n",
      "0.8478333333333333\n",
      "Epoch: 446  Iteration: 0\n",
      "0.848\n",
      "Epoch: 447  Iteration: 0\n",
      "0.84815\n",
      "Epoch: 448  Iteration: 0\n",
      "0.8482333333333333\n",
      "Epoch: 449  Iteration: 0\n",
      "0.8485333333333334\n",
      "Epoch: 450  Iteration: 0\n",
      "0.8487333333333333\n",
      "Epoch: 451  Iteration: 0\n",
      "0.8488833333333333\n",
      "Epoch: 452  Iteration: 0\n",
      "0.8488833333333333\n",
      "Epoch: 453  Iteration: 0\n",
      "0.8490333333333333\n",
      "Epoch: 454  Iteration: 0\n",
      "0.8491\n",
      "Epoch: 455  Iteration: 0\n",
      "0.8491833333333333\n",
      "Epoch: 456  Iteration: 0\n",
      "0.8493\n",
      "Epoch: 457  Iteration: 0\n",
      "0.8493833333333334\n",
      "Epoch: 458  Iteration: 0\n",
      "0.8495833333333334\n",
      "Epoch: 459  Iteration: 0\n",
      "0.8497666666666667\n",
      "Epoch: 460  Iteration: 0\n",
      "0.8500166666666666\n",
      "Epoch: 461  Iteration: 0\n",
      "0.8502\n",
      "Epoch: 462  Iteration: 0\n",
      "0.8503166666666667\n",
      "Epoch: 463  Iteration: 0\n",
      "0.85045\n",
      "Epoch: 464  Iteration: 0\n",
      "0.8506\n",
      "Epoch: 465  Iteration: 0\n",
      "0.8507666666666667\n",
      "Epoch: 466  Iteration: 0\n",
      "0.8508\n",
      "Epoch: 467  Iteration: 0\n",
      "0.8509166666666667\n",
      "Epoch: 468  Iteration: 0\n",
      "0.8511666666666666\n",
      "Epoch: 469  Iteration: 0\n",
      "0.85125\n",
      "Epoch: 470  Iteration: 0\n",
      "0.8513833333333334\n",
      "Epoch: 471  Iteration: 0\n",
      "0.8515166666666667\n",
      "Epoch: 472  Iteration: 0\n",
      "0.85175\n",
      "Epoch: 473  Iteration: 0\n",
      "0.8518833333333333\n",
      "Epoch: 474  Iteration: 0\n",
      "0.8519833333333333\n",
      "Epoch: 475  Iteration: 0\n",
      "0.8521166666666666\n",
      "Epoch: 476  Iteration: 0\n",
      "0.8522\n",
      "Epoch: 477  Iteration: 0\n",
      "0.8522833333333333\n",
      "Epoch: 478  Iteration: 0\n",
      "0.8523833333333334\n",
      "Epoch: 479  Iteration: 0\n",
      "0.8525166666666667\n",
      "Epoch: 480  Iteration: 0\n",
      "0.8526666666666667\n",
      "Epoch: 481  Iteration: 0\n",
      "0.8527833333333333\n",
      "Epoch: 482  Iteration: 0\n",
      "0.8528666666666667\n",
      "Epoch: 483  Iteration: 0\n",
      "0.8529833333333333\n",
      "Epoch: 484  Iteration: 0\n",
      "0.8531333333333333\n",
      "Epoch: 485  Iteration: 0\n",
      "0.8532833333333333\n",
      "Epoch: 486  Iteration: 0\n",
      "0.8533833333333334\n",
      "Epoch: 487  Iteration: 0\n",
      "0.8535333333333334\n",
      "Epoch: 488  Iteration: 0\n",
      "0.8536833333333333\n",
      "Epoch: 489  Iteration: 0\n",
      "0.8538\n",
      "Epoch: 490  Iteration: 0\n",
      "0.8539166666666667\n",
      "Epoch: 491  Iteration: 0\n",
      "0.8541\n",
      "Epoch: 492  Iteration: 0\n",
      "0.8541666666666666\n",
      "Epoch: 493  Iteration: 0\n",
      "0.8543666666666667\n",
      "Epoch: 494  Iteration: 0\n",
      "0.8544833333333334\n",
      "Epoch: 495  Iteration: 0\n",
      "0.8545833333333334\n",
      "Epoch: 496  Iteration: 0\n",
      "0.8546666666666667\n",
      "Epoch: 497  Iteration: 0\n",
      "0.8548\n",
      "Epoch: 498  Iteration: 0\n",
      "0.8549\n",
      "Epoch: 499  Iteration: 0\n",
      "0.8550166666666666\n"
     ]
    }
   ],
   "source": [
    "W1 = np.random.uniform(-0.5, 0.5, (10,784))\n",
    "b1 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "W2 = np.random.uniform(-0.5, 0.5, (10,10))\n",
    "b2 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "\n",
    "\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 60000//1\n",
    "iterations = train_X_flatten.T.shape[0]//batch_size\n",
    "learning_rate = 0.1\n",
    "\n",
    "# m = batch_size\n",
    "X = train_X_flatten # shape -> 784, m\n",
    "Y = train_y_onehot # shape -< 10, m\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        X = train_X_flatten.T[(iteration*batch_size):(iteration+1)*batch_size].T\n",
    "        Y = train_y_onehot.T[(iteration*batch_size):(iteration+1)*batch_size].T\n",
    "        # print(iter*batch_size)\n",
    "        # forward prop\n",
    "        Z1 = W1@X+b1\n",
    "        A1 = ReLU(Z1)\n",
    "        Z2 = W2@A1+b2\n",
    "        A2 = softmax(Z2)\n",
    "\n",
    "        # backward prop\n",
    "        dZ2 = A2-Y\n",
    "        dW2 = 1/m*dZ2@A1.T\n",
    "        db2 = 1/m*np.sum(dZ2)\n",
    "        dZ1 = W2.T@dZ2 * ReLU_deriv(Z1)\n",
    "        dW1 = 1/m*dZ1@X.T\n",
    "        db1 = 1/m*np.sum(dZ1)\n",
    "\n",
    "        # update poram\n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1    \n",
    "        W2 = W2 - learning_rate * dW2  \n",
    "        b2 = b2 - learning_rate * db2    \n",
    "\n",
    "        # accuracy\n",
    "        if iteration % 1 == 0 :\n",
    "            # print(A2)\n",
    "            print(\"Epoch:\", epoch, \" Iteration:\", iteration)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, train_y.T[(iteration*batch_size):(iteration+1)*batch_size].T))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_flatten.T[0:1].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a771f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 5151\n",
    "index = np.random.randint(0,1000)\n",
    "#plot_and_label_train_X(index)\n",
    "\n",
    "X = train_X_flatten.T[index:index+1].T\n",
    "y = train_y_onehot.T[index:index+1].T\n",
    "\n",
    "\n",
    "Z1 = W1@X+b1\n",
    "A1 = ReLU(Z1)\n",
    "Z2 = W2@A1+b2\n",
    "A2 = softmax(Z2)\n",
    "\n",
    "# print(Z1.shape, W1.shape, X.shape) # -> HOW????\n",
    "print(np.argmax(A2), np.argmax(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05665cec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "W1 = np.random.uniform(-0.5, 0.5, (10,784))\n",
    "b1 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "W2 = np.random.uniform(-0.5, 0.5, (10,10))\n",
    "b2 = np.random.uniform(-0.5, 0.5, (10,1))\n",
    "\n",
    "learning_rate = 0.05\n",
    "iterations = 100\n",
    "\n",
    "\n",
    "\n",
    "m = 20000\n",
    "for i in range(0,60000, m):\n",
    "    X = train_X_flatten.T[i:i+m].T # shape -> 784, m\n",
    "    Y = train_y_onehot.T[i:i+m].T\n",
    "    print(i)\n",
    "    for iter in range(iterations):\n",
    "        # forward prop\n",
    "        Z1 = W1@X+b1\n",
    "        A1 = ReLU(Z1)\n",
    "        Z2 = W2@A1+b2\n",
    "        A2 = softmax(Z2)\n",
    "\n",
    "        # backward prop\n",
    "        dZ2 = A2-Y            \n",
    "        dW2 = 1/m*dZ2@A1.T\n",
    "        db2 = 1/m*np.sum(dZ2)\n",
    "        dZ1 = W2.T@dZ2 * ReLU_deriv(Z1)\n",
    "        dW1 = 1/m*dZ1@X.T\n",
    "        db1 = 1/m*np.sum(dZ1)\n",
    "\n",
    "        # update poram\n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1    \n",
    "        W2 = W2 - learning_rate * dW2  \n",
    "        b2 = b2 - learning_rate * db2    \n",
    "\n",
    "       # accuracy\n",
    "        if iter % 10 == 0 :\n",
    "            # print(A2)\n",
    "            print(\"Iteration: \", iter)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, train_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0,1000)\n",
    "plot_and_label_train_X(index)\n",
    "\n",
    "X = train_X_flatten.T[index:index+1].T # shape -> 784, m\n",
    "Y = train_y_onehot.T[index:index+1].T\n",
    "\n",
    "#print(X.shape)\n",
    "Z1 = W1@X+b1\n",
    "A1 = ReLU(Z1)\n",
    "Z2 = W2@A1+b2\n",
    "A2 = ReLU(Z2)\n",
    "print(A2.T[0])\n",
    "print(\"guess: \", np.argmax(A2.T[0]), \"| certainty: \" ,np.max(A2.T[0]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "spiral_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
